 # Copyright (c) 2018, NVIDIA CORPORATION. All rights reserved.
 #
 # Permission is hereby granted, free of charge, to any person obtaining a
 # copy of this software and associated documentation files (the "Software"),
 # to deal in the Software without restriction, including without limitation
 # the rights to use, copy, modify, merge, publish, distribute, sublicense,
 # and/or sell copies of the Software, and to permit persons to whom the
 # Software is furnished to do so, subject to the following conditions:
 #
 # The above copyright notice and this permission notice shall be included in
 # all copies or substantial portions of the Software.
 #
 # THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 # IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 # FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
 # THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 # FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 # DEALINGS IN THE SOFTWARE.

name: "FD_LPD_Redactor"
input: "data"
input_dim: 1
input_dim: 3
input_dim: 270
input_dim: 480

# **********************************************************
# LPD Model resnet10
# **********************************************************
layer {
  name: "conv1_branch_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_branch_1"
  convolution_param {
    num_output: 64
    pad_h: 3
    pad_w: 3
    kernel_h: 7
    kernel_w: 7
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "bn_conv1_branch_1"
  type: "Scale"
  bottom: "conv1_branch_1"
  top: "bn_conv1_branch_1"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "activation_1/Relu_branch_1"
  type: "ReLU"
  bottom: "bn_conv1_branch_1"
  top: "activation_1/Relu_branch_1"
}
layer {
  name: "block_1a_conv_1_branch_1"
  type: "Convolution"
  bottom: "activation_1/Relu_branch_1"
  top: "block_1a_conv_1_branch_1"
  convolution_param {
    num_output: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "block_1a_conv_shortcut_branch_1"
  type: "Convolution"
  bottom: "activation_1/Relu_branch_1"
  top: "block_1a_conv_shortcut_branch_1"
  convolution_param {
    num_output: 64
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "block_1a_bn_1_branch_1"
  type: "Scale"
  bottom: "block_1a_conv_1_branch_1"
  top: "block_1a_bn_1_branch_1"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "block_1a_bn_shortcut_branch_1"
  type: "Scale"
  bottom: "block_1a_conv_shortcut_branch_1"
  top: "block_1a_bn_shortcut_branch_1"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "activation_2/Relu_branch_1"
  type: "ReLU"
  bottom: "block_1a_bn_1_branch_1"
  top: "activation_2/Relu_branch_1"
}
layer {
  name: "block_1a_conv_2_branch_1"
  type: "Convolution"
  bottom: "activation_2/Relu_branch_1"
  top: "block_1a_conv_2_branch_1"
  convolution_param {
    num_output: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "block_1a_bn_2_branch_1"
  type: "Scale"
  bottom: "block_1a_conv_2_branch_1"
  top: "block_1a_bn_2_branch_1"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "add_1_branch_1"
  type: "Eltwise"
  bottom: "block_1a_bn_shortcut_branch_1"
  bottom: "block_1a_bn_2_branch_1"
  top: "add_1_branch_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "activation_3/Relu_branch_1"
  type: "ReLU"
  bottom: "add_1_branch_1"
  top: "activation_3/Relu_branch_1"
}
layer {
  name: "block_2a_conv_1_branch_1"
  type: "Convolution"
  bottom: "activation_3/Relu_branch_1"
  top: "block_2a_conv_1_branch_1"
  convolution_param {
    num_output: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "block_2a_conv_shortcut_branch_1"
  type: "Convolution"
  bottom: "activation_3/Relu_branch_1"
  top: "block_2a_conv_shortcut_branch_1"
  convolution_param {
    num_output: 128
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "block_2a_bn_1_branch_1"
  type: "Scale"
  bottom: "block_2a_conv_1_branch_1"
  top: "block_2a_bn_1_branch_1"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "block_2a_bn_shortcut_branch_1"
  type: "Scale"
  bottom: "block_2a_conv_shortcut_branch_1"
  top: "block_2a_bn_shortcut_branch_1"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "activation_4/Relu_branch_1"
  type: "ReLU"
  bottom: "block_2a_bn_1_branch_1"
  top: "activation_4/Relu_branch_1"
}
layer {
  name: "block_2a_conv_2_branch_1"
  type: "Convolution"
  bottom: "activation_4/Relu_branch_1"
  top: "block_2a_conv_2_branch_1"
  convolution_param {
    num_output: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "block_2a_bn_2_branch_1"
  type: "Scale"
  bottom: "block_2a_conv_2_branch_1"
  top: "block_2a_bn_2_branch_1"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "add_2_branch_1"
  type: "Eltwise"
  bottom: "block_2a_bn_shortcut_branch_1"
  bottom: "block_2a_bn_2_branch_1"
  top: "add_2_branch_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "activation_5/Relu_branch_1"
  type: "ReLU"
  bottom: "add_2_branch_1"
  top: "activation_5/Relu_branch_1"
}
layer {
  name: "block_3a_conv_1_branch_1"
  type: "Convolution"
  bottom: "activation_5/Relu_branch_1"
  top: "block_3a_conv_1_branch_1"
  convolution_param {
    num_output: 256
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "block_3a_conv_shortcut_branch_1"
  type: "Convolution"
  bottom: "activation_5/Relu_branch_1"
  top: "block_3a_conv_shortcut_branch_1"
  convolution_param {
    num_output: 256
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "block_3a_bn_1_branch_1"
  type: "Scale"
  bottom: "block_3a_conv_1_branch_1"
  top: "block_3a_bn_1_branch_1"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "block_3a_bn_shortcut_branch_1"
  type: "Scale"
  bottom: "block_3a_conv_shortcut_branch_1"
  top: "block_3a_bn_shortcut_branch_1"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "activation_6/Relu_branch_1"
  type: "ReLU"
  bottom: "block_3a_bn_1_branch_1"
  top: "activation_6/Relu_branch_1"
}
layer {
  name: "block_3a_conv_2_branch_1"
  type: "Convolution"
  bottom: "activation_6/Relu_branch_1"
  top: "block_3a_conv_2_branch_1"
  convolution_param {
    num_output: 256
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "block_3a_bn_2_branch_1"
  type: "Scale"
  bottom: "block_3a_conv_2_branch_1"
  top: "block_3a_bn_2_branch_1"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "add_3_branch_1"
  type: "Eltwise"
  bottom: "block_3a_bn_shortcut_branch_1"
  bottom: "block_3a_bn_2_branch_1"
  top: "add_3_branch_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "activation_7/Relu_branch_1"
  type: "ReLU"
  bottom: "add_3_branch_1"
  top: "activation_7/Relu_branch_1"
}
layer {
  name: "block_4a_conv_1_branch_1"
  type: "Convolution"
  bottom: "activation_7/Relu_branch_1"
  top: "block_4a_conv_1_branch_1"
  convolution_param {
    num_output: 512
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "block_4a_conv_shortcut_branch_1"
  type: "Convolution"
  bottom: "activation_7/Relu_branch_1"
  top: "block_4a_conv_shortcut_branch_1"
  convolution_param {
    num_output: 512
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "block_4a_bn_1_branch_1"
  type: "Scale"
  bottom: "block_4a_conv_1_branch_1"
  top: "block_4a_bn_1_branch_1"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "block_4a_bn_shortcut_branch_1"
  type: "Scale"
  bottom: "block_4a_conv_shortcut_branch_1"
  top: "block_4a_bn_shortcut_branch_1"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "activation_8/Relu_branch_1"
  type: "ReLU"
  bottom: "block_4a_bn_1_branch_1"
  top: "activation_8/Relu_branch_1"
}
layer {
  name: "block_4a_conv_2_branch_1"
  type: "Convolution"
  bottom: "activation_8/Relu_branch_1"
  top: "block_4a_conv_2_branch_1"
  convolution_param {
    num_output: 512
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "block_4a_bn_2_branch_1"
  type: "Scale"
  bottom: "block_4a_conv_2_branch_1"
  top: "block_4a_bn_2_branch_1"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "add_4_branch_1"
  type: "Eltwise"
  bottom: "block_4a_bn_shortcut_branch_1"
  bottom: "block_4a_bn_2_branch_1"
  top: "add_4_branch_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "activation_9/Relu_branch_1"
  type: "ReLU"
  bottom: "add_4_branch_1"
  top: "activation_9/Relu_branch_1"
}
layer {
  name: "conv2d_bbox_branch_1"
  type: "Convolution"
  bottom: "activation_9/Relu_branch_1"
  top: "conv2d_bbox_branch_1"
  convolution_param {
    num_output: 12
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2d_cov_branch_1"
  type: "Convolution"
  bottom: "activation_9/Relu_branch_1"
  top: "conv2d_cov_branch_1"
  convolution_param {
    num_output: 3
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2d_cov/Sigmoid_branch_1"
  type: "Sigmoid"
  bottom: "conv2d_cov_branch_1"
  top: "conv2d_cov/Sigmoid_branch_1"
}

# **********************************************************
# Face detect model
# **********************************************************

layer {
  name: "conv1_branch_2"
  type: "Convolution"
  bottom: "data"
  top: "conv1_branch_2"
  convolution_param {
    num_output: 48
    pad_h: 3
    pad_w: 3
    kernel_h: 7
    kernel_w: 7
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "bn_conv1_branch_2"
  type: "Scale"
  bottom: "conv1_branch_2"
  top: "bn_conv1_branch_2"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "activation_1/Relu_branch_2"
  type: "ReLU"
  bottom: "bn_conv1_branch_2"
  top: "activation_1/Relu_branch_2"
}
layer {
  name: "block_1a_conv_1_branch_2"
  type: "Convolution"
  bottom: "activation_1/Relu_branch_2"
  top: "block_1a_conv_1_branch_2"
  convolution_param {
    num_output: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "block_1a_conv_shortcut_branch_2"
  type: "Convolution"
  bottom: "activation_1/Relu_branch_2"
  top: "block_1a_conv_shortcut_branch_2"
  convolution_param {
    num_output: 64
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "block_1a_bn_1_branch_2"
  type: "Scale"
  bottom: "block_1a_conv_1_branch_2"
  top: "block_1a_bn_1_branch_2"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "block_1a_bn_shortcut_branch_2"
  type: "Scale"
  bottom: "block_1a_conv_shortcut_branch_2"
  top: "block_1a_bn_shortcut_branch_2"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "activation_2/Relu_branch_2"
  type: "ReLU"
  bottom: "block_1a_bn_1_branch_2"
  top: "activation_2/Relu_branch_2"
}
layer {
  name: "block_1a_conv_2_branch_2"
  type: "Convolution"
  bottom: "activation_2/Relu_branch_2"
  top: "block_1a_conv_2_branch_2"
  convolution_param {
    num_output: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "block_1a_bn_2_branch_2"
  type: "Scale"
  bottom: "block_1a_conv_2_branch_2"
  top: "block_1a_bn_2_branch_2"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "add_1_branch_2"
  type: "Eltwise"
  bottom: "block_1a_bn_shortcut_branch_2"
  bottom: "block_1a_bn_2_branch_2"
  top: "add_1_branch_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "activation_3/Relu_branch_2"
  type: "ReLU"
  bottom: "add_1_branch_2"
  top: "activation_3/Relu_branch_2"
}
layer {
  name: "block_2a_conv_1_branch_2"
  type: "Convolution"
  bottom: "activation_3/Relu_branch_2"
  top: "block_2a_conv_1_branch_2"
  convolution_param {
    num_output: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "block_2a_conv_shortcut_branch_2"
  type: "Convolution"
  bottom: "activation_3/Relu_branch_2"
  top: "block_2a_conv_shortcut_branch_2"
  convolution_param {
    num_output: 128
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "block_2a_bn_1_branch_2"
  type: "Scale"
  bottom: "block_2a_conv_1_branch_2"
  top: "block_2a_bn_1_branch_2"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "block_2a_bn_shortcut_branch_2"
  type: "Scale"
  bottom: "block_2a_conv_shortcut_branch_2"
  top: "block_2a_bn_shortcut_branch_2"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "activation_4/Relu_branch_2"
  type: "ReLU"
  bottom: "block_2a_bn_1_branch_2"
  top: "activation_4/Relu_branch_2"
}
layer {
  name: "block_2a_conv_2_branch_2"
  type: "Convolution"
  bottom: "activation_4/Relu_branch_2"
  top: "block_2a_conv_2_branch_2"
  convolution_param {
    num_output: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "block_2a_bn_2_branch_2"
  type: "Scale"
  bottom: "block_2a_conv_2_branch_2"
  top: "block_2a_bn_2_branch_2"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "add_2_branch_2"
  type: "Eltwise"
  bottom: "block_2a_bn_shortcut_branch_2"
  bottom: "block_2a_bn_2_branch_2"
  top: "add_2_branch_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "activation_5/Relu_branch_2"
  type: "ReLU"
  bottom: "add_2_branch_2"
  top: "activation_5/Relu_branch_2"
}
layer {
  name: "block_3a_conv_1_branch_2"
  type: "Convolution"
  bottom: "activation_5/Relu_branch_2"
  top: "block_3a_conv_1_branch_2"
  convolution_param {
    num_output: 160
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "block_3a_conv_shortcut_branch_2"
  type: "Convolution"
  bottom: "activation_5/Relu_branch_2"
  top: "block_3a_conv_shortcut_branch_2"
  convolution_param {
    num_output: 128
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "block_3a_bn_1_branch_2"
  type: "Scale"
  bottom: "block_3a_conv_1_branch_2"
  top: "block_3a_bn_1_branch_2"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "block_3a_bn_shortcut_branch_2"
  type: "Scale"
  bottom: "block_3a_conv_shortcut_branch_2"
  top: "block_3a_bn_shortcut_branch_2"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "activation_6/Relu_branch_2"
  type: "ReLU"
  bottom: "block_3a_bn_1_branch_2"
  top: "activation_6/Relu_branch_2"
}
layer {
  name: "block_3a_conv_2_branch_2"
  type: "Convolution"
  bottom: "activation_6/Relu_branch_2"
  top: "block_3a_conv_2_branch_2"
  convolution_param {
    num_output: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "block_3a_bn_2_branch_2"
  type: "Scale"
  bottom: "block_3a_conv_2_branch_2"
  top: "block_3a_bn_2_branch_2"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "add_3_branch_2"
  type: "Eltwise"
  bottom: "block_3a_bn_shortcut_branch_2"
  bottom: "block_3a_bn_2_branch_2"
  top: "add_3_branch_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "activation_7/Relu_branch_2"
  type: "ReLU"
  bottom: "add_3_branch_2"
  top: "activation_7/Relu_branch_2"
}
layer {
  name: "block_4a_conv_1_branch_2"
  type: "Convolution"
  bottom: "activation_7/Relu_branch_2"
  top: "block_4a_conv_1_branch_2"
  convolution_param {
    num_output: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "block_4a_conv_shortcut_branch_2"
  type: "Convolution"
  bottom: "activation_7/Relu_branch_2"
  top: "block_4a_conv_shortcut_branch_2"
  convolution_param {
    num_output: 88
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "block_4a_bn_1_branch_2"
  type: "Scale"
  bottom: "block_4a_conv_1_branch_2"
  top: "block_4a_bn_1_branch_2"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "block_4a_bn_shortcut_branch_2"
  type: "Scale"
  bottom: "block_4a_conv_shortcut_branch_2"
  top: "block_4a_bn_shortcut_branch_2"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "activation_8/Relu_branch_2"
  type: "ReLU"
  bottom: "block_4a_bn_1_branch_2"
  top: "activation_8/Relu_branch_2"
}
layer {
  name: "block_4a_conv_2_branch_2"
  type: "Convolution"
  bottom: "activation_8/Relu_branch_2"
  top: "block_4a_conv_2_branch_2"
  convolution_param {
    num_output: 88
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "block_4a_bn_2_branch_2"
  type: "Scale"
  bottom: "block_4a_conv_2_branch_2"
  top: "block_4a_bn_2_branch_2"
  scale_param {
    axis: 1
    bias_term: true
  }
}
layer {
  name: "add_4_branch_2"
  type: "Eltwise"
  bottom: "block_4a_bn_shortcut_branch_2"
  bottom: "block_4a_bn_2_branch_2"
  top: "add_4_branch_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "activation_9/Relu_branch_2"
  type: "ReLU"
  bottom: "add_4_branch_2"
  top: "activation_9/Relu_branch_2"
}
layer {
  name: "output_bbox_branch_2"
  type: "Convolution"
  bottom: "activation_9/Relu_branch_2"
  top: "output_bbox_branch_2"
  convolution_param {
    num_output: 4
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "output_cov_branch_2"
  type: "Convolution"
  bottom: "activation_9/Relu_branch_2"
  top: "output_cov_branch_2"
  convolution_param {
    num_output: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "output_cov/Sigmoid_branch_2"
  type: "Sigmoid"
  bottom: "output_cov_branch_2"
  top: "output_cov/Sigmoid_branch_2"
}

# *************************************************
# Combining outputs
# *************************************************

layer {
  name: "concatenate_cov"
  type: "Concat"
  bottom: "output_cov/Sigmoid_branch_2"
  bottom: "conv2d_cov/Sigmoid_branch_1"
  top: "output_cov"
  concat_param {
    axis: 1
  }
}
layer {
  name: "concatenate_bbox"
  type: "Concat"
  bottom: "output_bbox_branch_2"
  bottom: "conv2d_bbox_branch_1"
  top: "output_bbox"
  concat_param {
    axis: 1
  }
}
